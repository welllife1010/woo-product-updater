const fs = require("fs");
const path = require("path");
const { logErrorToFile, logInfoToFile } = require("./logger");
const { batchQueue, appRedis } = require('./queue');
const checkpointFilePath = path.join(__dirname, "process_checkpoint.json");

// ‚úÖ **Ensure `process_checkpoint.json` is always present at script start**
if (!fs.existsSync(checkpointFilePath)) {
  logInfoToFile(`‚ö†Ô∏è process_checkpoint.json not found. Creating a new one.`);
  fs.writeFileSync(checkpointFilePath, JSON.stringify({}, null, 2)); // Create an empty JSON file
}

/**
 * Save progress / checkpoint to a local JSON file.
 *
 * Single-worker scenario: We don't need to store `lastProcessedRow`
 * in Redis. Instead, we just pass it in or compute it, then write it
 * to `process_checkpoint.json`.
 */
async function saveCheckpoint(fileKey, lastProcessedRow, totalRows) {

  logInfoToFile(`üîç Debug: saveCheckpoint() called!`);
  logInfoToFile(`üîç Debug: saveCheckpoint called with fileKey=${fileKey} (${typeof fileKey}), lastProcessedRow=${lastProcessedRow} (${typeof lastProcessedRow}), totalRows=${totalRows} (${typeof totalRows})`);

  // Validate arguments with detailed logging
  if (!fileKey || typeof fileKey !== "string") {
    logErrorToFile(`‚ùå saveCheckpoint received invalid fileKey. Type: ${typeof fileKey}, Value: ${JSON.stringify(fileKey)}`);
    return;
  }
  if (!Number.isInteger(totalRows) || totalRows < 0) {
    logErrorToFile(`‚ùå saveCheckpoint received invalid totalRows: ${JSON.stringify(totalRows)}`);
    return;
  }
  if (!Number.isInteger(lastProcessedRow) || lastProcessedRow < 0) {
    logErrorToFile(`‚ùå saveCheckpoint received invalid lastProcessedRow: ${JSON.stringify(lastProcessedRow)}`);
    return;
  }

  // ‚úÖ Ensure the checkpoint file exists before writing
  if (!fs.existsSync(checkpointFilePath)) {
    logInfoToFile(`‚ö†Ô∏è process_checkpoint.json not found. Creating a new one.`);
    fs.writeFileSync(checkpointFilePath, JSON.stringify({}, null, 2));
  }
  
  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  // 1) Fetch Row-Level Stats (Optional)
  //    Use Redis to track updated/skipped/failed products.
  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  const updated = parseInt(await appRedis.get(`updated-products:${fileKey}`) || 0, 10);
  const skipped = parseInt(await appRedis.get(`skipped-products:${fileKey}`) || 0, 10);
  const failed  = parseInt(await appRedis.get(`failed-products:${fileKey}`)  || 0, 10);

  const completedRows = updated + skipped + failed;
  const remainingRows = totalRows - completedRows;

  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  // 2) (Optional) Gather Queue-Wide Job Stats
  //    Even with 1 worker, we can store how many jobs are left.
  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  const waiting = await batchQueue.getWaitingCount();
  const active  = await batchQueue.getActiveCount();
  const delayed = await batchQueue.getDelayedCount();
  const totalRemainingJobs = waiting + active + delayed;

  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  // 3) Read Existing Checkpoint Data From JSON
  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  
  // ‚úÖ Log before updating
  logInfoToFile(`üìå Debug: Updating process_checkpoint.json with new data.`);

  let checkpoints = {};
  try {
    const fileData = fs.readFileSync(checkpointFilePath, "utf-8");
    checkpoints = JSON.parse(fileData);
  } catch (error) {
    logErrorToFile(`‚ùå Error reading checkpoint file: ${error.message}`);
    // If parse fails, we fallback to an empty object
    checkpoints = {};
  }
  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  // 4) Update the Checkpoints Object
  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  checkpoints[fileKey] = {
    rowLevel: {
      lastProcessedRow,    // Single-worker approach: stored in local file
      totalRows,
      updated,
      skipped,
      failed,
      completedRows,
      remainingRows
    },
    jobLevel: {
      waiting,
      active,
      delayed,
      totalRemainingJobs
    },
    timestamp: new Date().toISOString()
  };

  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  // 5) Write Updated Checkpoints to File
  // ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  try {
    fs.writeFileSync(checkpointFilePath, JSON.stringify(checkpoints, null, 2));
    logInfoToFile(
      `üìå Progress saved for ${fileKey} => ` +
      `Rows: completed ${completedRows}/${totalRows} (lastProcessedRow=${lastProcessedRow}) | ` +
      `Jobs: remaining ${totalRemainingJobs}`
    );
  } catch (error) {
    logErrorToFile(`‚ùå Failed to save checkpoint for ${fileKey}: ${error.message}`);
  }
}

/**
 * getLastProcessedRow returns the lastProcessedRow stored in `process_checkpoint.json`.
 */
function getLastProcessedRow(fileKey) {

  logInfoToFile(`"getLastProcessedRow" - Start to check the lastProcessRow value for fileKey=${fileKey}`);

    if (!fileKey || typeof fileKey !== "string") {
      logErrorToFile(`‚ùå getLastProcessedRow missing valid fileKey`);
      return 0;
    }
  
    // ‚úÖ Ensure the checkpoint file exists
    if (!fs.existsSync(checkpointFilePath)) {
      logInfoToFile(`‚ö†Ô∏è process_checkpoint.json not found. Creating a new one.`);
      fs.writeFileSync(checkpointFilePath, JSON.stringify({}, null, 2));
      return 0; // No previous progress
    }
  
    try {
      const fileData = fs.readFileSync(checkpointFilePath, "utf-8");
      const checkpoints = JSON.parse(fileData);
  
      if (!checkpoints[fileKey]) {
        logInfoToFile(`No checkpoint entry found for fileKey=${fileKey}, returning 0`);
        return 0;
      }
  
      // The structure here matches what we wrote in saveCheckpoint
      const lastProcessedRow = checkpoints[fileKey].rowLevel?.lastProcessedRow;

      logInfoToFile(`"getLastProcessedRow" - lastProcessedRow=${lastProcessedRow} for fileKey=${fileKey}`);

      if (typeof lastProcessedRow === "number") {
        return lastProcessedRow;
      } else {
        logInfoToFile(`No valid lastProcessedRow for fileKey=${fileKey} in checkpoint, returning 0`);
        return 0;
      }
    } catch (error) {
      logErrorToFile(`‚ùå Error reading getLastProcessedRow: ${error.message}`);
      return 0;
    }
}

module.exports = {
    saveCheckpoint,
    getLastProcessedRow,
};