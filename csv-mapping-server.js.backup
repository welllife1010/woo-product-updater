// csv-mapping-server.js
//
// Small Express server that provides:
//  - API for listing CSV mappings
//  - API for saving column mappings
//  - API for uploading CSVs (stores in S3 + registers header mapping)
//  - Static HTML UI for admin users to interact with these APIs.

const express = require("express");
const fs = require("fs");
const path = require("path");
const multer = require("multer");
const { S3Client, PutObjectCommand } = require("@aws-sdk/client-s3");
const csvParser = require("csv-parser");

const app = express();
const PORT = process.env.CSV_MAPPING_PORT || 4000;
const MAPPINGS_PATH = path.join(__dirname, "csv-mappings.json");

const executionMode = process.env.EXECUTION_MODE || "production";
const S3_BUCKET_NAME = (executionMode === "development" || executionMode === "test")
  ? process.env.S3_BUCKET_NAME_TEST
  : process.env.S3_BUCKET_NAME;
const AWS_REGION = process.env.AWS_REGION || "us-west-1";

const s3Client = new S3Client({ region: AWS_REGION });

// For handling file uploads to the server
const upload = multer({ dest: path.join(__dirname, "tmp-uploads") });

app.use(express.json());

// ---------------------- helper: mapping store ----------------------

function loadMappings() {
  if (!fs.existsSync(MAPPINGS_PATH)) {
    return { files: [] };
  }
  return JSON.parse(fs.readFileSync(MAPPINGS_PATH, "utf8"));
}

function saveMappings(store) {
  fs.writeFileSync(MAPPINGS_PATH, JSON.stringify(store, null, 2));
}

// read header row from a local CSV path
async function getHeadersForCsv(localPath) {
  return new Promise((resolve, reject) => {
    fs.createReadStream(localPath)
      .pipe(csvParser())
      .on("headers", (headers) => {
        resolve(headers);
      })
      .on("error", reject);
  });
}

// Register a new fileKey + headers in csv-mappings.json
async function registerNewCsv(fileKey, localPath) {
  const headers = await getHeadersForCsv(localPath);

  const store = loadMappings();
  const exists = store.files.find((f) => f.fileKey === fileKey);
  if (!exists) {
    store.files.push({
      fileKey,
      status: "pending",
      headers,
      mapping: null,
      uploadedAt: new Date().toISOString(),
    });
    saveMappings(store);
  }
}

// ---------------------- API: mappings ----------------------

// GET /api/csv-mappings
// List all files + statuses.
app.get("/api/csv-mappings", (req, res) => {
  const store = loadMappings();
  res.json(store.files);
});

// GET /api/csv-mappings/:fileKey
// Return one file (with headers + current mapping).
app.get("/api/csv-mappings/:fileKey", (req, res) => {
  const fileKey = req.params.fileKey;
  const store = loadMappings();
  const entry = store.files.find((f) => f.fileKey === fileKey);
  if (!entry) {
    return res.status(404).json({ error: "Not found" });
  }
  res.json(entry);
});

// POST /api/csv-mappings/:fileKey
// Body: { partNumber, category, manufacturer }
app.post("/api/csv-mappings/:fileKey", (req, res) => {
  const fileKey = req.params.fileKey;
  const { partNumber, category, manufacturer } = req.body;

  if (!partNumber || !category || !manufacturer) {
    return res
      .status(400)
      .json({ error: "partNumber, category, manufacturer are required." });
  }

  const store = loadMappings();
  const entry = store.files.find((f) => f.fileKey === fileKey);
  if (!entry) {
    return res.status(404).json({ error: "File not found" });
  }

  entry.mapping = { partNumber, category, manufacturer };
  entry.status = "ready";
  saveMappings(store);

  res.json({ ok: true, entry });
});

// ---------------------- API: upload CSV ----------------------
//
// POST /api/upload-csv
//   form-data fields:
//     - file: (the CSV file)
//     - folder (optional): S3 folder prefix, e.g. "20250312/" or "ui-uploads/20250312/"
//
// Behavior:
//   1. Save file temporarily
//   2. Upload to S3 at: key = folder + originalName
//   3. Register new CSV with its header row and status "pending"
//   4. Return fileKey so batch system can use it later.

/**
 * POST /api/upload-csv - Upload a CSV file to S3 and register for mapping.
 * 
 * BUG FIX (2025): Missing temp file cleanup on errors
 * 
 * PROBLEM:
 * The original code only cleaned up the temp file on success (fs.unlinkSync).
 * If S3 upload failed or any other error occurred, the temp file would remain
 * on disk indefinitely, potentially filling up the server's storage.
 * 
 * THE FIX:
 * Use try-finally to ensure temp file is ALWAYS cleaned up, regardless of
 * whether the operation succeeded or failed.
 * 
 * Request body (form-data):
 *   - file: The CSV file to upload
 *   - folder: Optional S3 folder prefix (e.g., "vendor-uploads/2025/")
 * 
 * Response:
 *   - { ok: true, fileKey, message } on success
 *   - { error: string } on failure
 */
app.post(
  "/api/upload-csv",
  upload.single("file"),
  async (req, res) => {
    // BUG FIX: Track temp file path for cleanup in finally block
    const tempFilePath = req.file?.path;
    
    try {
      if (!req.file) {
        return res.status(400).json({ error: "No file uploaded." });
      }
      if (!S3_BUCKET_NAME) {
        return res
          .status(500)
          .json({ error: "S3_BUCKET_NAME env var is not set." });
      }

      // Determine S3 folder / prefix
      const userFolder = req.body.folder || ""; // may be empty
      // Default: ui-uploads/YYYYMMDD/
      let prefix;
      if (userFolder.trim()) {
        prefix = userFolder.trim();
      } else {
        const today = new Date();
        const y = today.getFullYear();
        const m = String(today.getMonth() + 1).padStart(2, "0");
        const d = String(today.getDate()).padStart(2, "0");
        prefix = `ui-uploads/${y}${m}${d}/`;
      }
      // Ensure prefix ends with '/'
      if (!prefix.endsWith("/")) {
        prefix += "/";
      }

      const originalName = req.file.originalname;
      const fileKey = `${prefix}${originalName}`;

      // Upload to S3
      const fileStream = fs.createReadStream(req.file.path);

      await s3Client.send(
        new PutObjectCommand({
          Bucket: S3_BUCKET_NAME,
          Key: fileKey,
          Body: fileStream,
          ContentType: "text/csv",
        })
      );

      // Register the CSV with its header row for mapping
      await registerNewCsv(fileKey, req.file.path);

      res.json({
        ok: true,
        fileKey,
        message: "File uploaded to S3 and registered for mapping.",
      });
    } catch (err) {
      console.error("Upload error:", err);
      res.status(500).json({ error: "Upload failed." });
    } finally {
      // BUG FIX: Always clean up temp file, even on error
      if (tempFilePath && fs.existsSync(tempFilePath)) {
        try {
          fs.unlinkSync(tempFilePath);
          console.log(`[upload-csv] Cleaned up temp file: ${tempFilePath}`);
        } catch (cleanupErr) {
          // Log but don't throw - cleanup failure shouldn't break the response
          console.error(`[upload-csv] Failed to clean up temp file ${tempFilePath}: ${cleanupErr.message}`);
        }
      }
    }
  }
);

// ---------------------- Static UI ----------------------

app.use(express.static(path.join(__dirname, "csv-mapping-ui")));

app.listen(PORT, () => {
  console.log(`CSV Mapping UI running on http://localhost:${PORT}`);
});

// ============================================================================
// PROGRESS & ACTION ENDPOINTS
// ============================================================================

// GET /api/csv-mappings/:fileKey/progress - Get processing progress for a file
app.get("/api/csv-mappings/:fileKey/progress", async (req, res) => {
  try {
    const fileKey = decodeURIComponent(req.params.fileKey);
    const cleanFileKey = fileKey.replace(/\.csv$/i, "").replace(/\//g, "_");
    
    // Check batch_status directory
    const batchStatusPath = path.join(
      __dirname,
      "batch_status",
      fileKey.replace(/\.csv$/i, "").replace(/\//g, "/"),
      "batch_status.json"
    );
    
    // Check checkpoint file
    const checkpointPath = path.join(__dirname, "process_checkpoint.json");
    
    let progress = {
      status: "pending",
      processedRows: 0,
      totalRows: 0,
      updated: 0,
      skipped: 0,
      failed: 0,
      percentage: 0,
      missingProductsCount: 0,
      missingProductsFile: null
    };
    
    // Try to read checkpoint
    if (fs.existsSync(checkpointPath)) {
      try {
        const checkpoint = JSON.parse(fs.readFileSync(checkpointPath, "utf8"));
        if (checkpoint[fileKey]) {
          const cp = checkpoint[fileKey];
          if (cp.rowLevel) {
            progress.processedRows = cp.rowLevel.lastProcessedRow || 0;
            progress.totalRows = cp.rowLevel.totalRows || 0;
            progress.updated = cp.rowLevel.updated || 0;
            progress.skipped = cp.rowLevel.skipped || 0;
            progress.failed = cp.rowLevel.failed || 0;
            progress.percentage = progress.totalRows > 0 
              ? Math.round((progress.processedRows / progress.totalRows) * 100) 
              : 0;
            progress.status = progress.processedRows >= progress.totalRows ? "completed" : "processing";
          } else if (cp.lastProcessedRow !== undefined) {
            progress.processedRows = cp.lastProcessedRow;
            progress.status = "processing";
          }
        }
      } catch (e) {
        console.error("Error reading checkpoint:", e.message);
      }
    }
    
    // Check for missing products files
    const missingProductsDir = path.join(__dirname, "missing-products");
    if (fs.existsSync(missingProductsDir)) {
      const categories = fs.readdirSync(missingProductsDir);
      for (const cat of categories) {
        const catPath = path.join(missingProductsDir, cat);
        if (fs.statSync(catPath).isDirectory()) {
          const files = fs.readdirSync(catPath);
          const matchingFile = files.find(f => f.includes(cleanFileKey));
          if (matchingFile) {
            const filePath = path.join(catPath, matchingFile);
            try {
              const missingData = JSON.parse(fs.readFileSync(filePath, "utf8"));
              progress.missingProductsCount = missingData.length;
              progress.missingProductsFile = `${cat}/${matchingFile}`;
            } catch (e) {
              console.error("Error reading missing products:", e.message);
            }
          }
        }
      }
    }
    
    res.json(progress);
  } catch (err) {
    console.error("Progress endpoint error:", err);
    res.status(500).json({ error: err.message });
  }
});

// POST /api/csv-mappings/:fileKey/reprocess - Reset and reprocess a file
app.post("/api/csv-mappings/:fileKey/reprocess", async (req, res) => {
  try {
    const fileKey = decodeURIComponent(req.params.fileKey);
    const cleanFileKey = fileKey.replace(/\.csv$/i, "").replace(/\//g, "_");
    
    // 1. Remove from checkpoint
    const checkpointPath = path.join(__dirname, "process_checkpoint.json");
    if (fs.existsSync(checkpointPath)) {
      try {
        const checkpoint = JSON.parse(fs.readFileSync(checkpointPath, "utf8"));
        if (checkpoint[fileKey]) {
          delete checkpoint[fileKey];
          fs.writeFileSync(checkpointPath, JSON.stringify(checkpoint, null, 2));
        }
      } catch (e) {
        console.error("Error updating checkpoint:", e.message);
      }
    }
    
    // 2. Remove batch_status for this file
    const batchDir = path.join(
      __dirname,
      "batch_status",
      fileKey.replace(/\.csv$/i, "").split("/").slice(0, -1).join("/")
    );
    if (fs.existsSync(batchDir)) {
      fs.rmSync(batchDir, { recursive: true, force: true });
    }
    
    // 3. Remove missing products files for this file
    const missingProductsDir = path.join(__dirname, "missing-products");
    if (fs.existsSync(missingProductsDir)) {
      const categories = fs.readdirSync(missingProductsDir);
      for (const cat of categories) {
        const catPath = path.join(missingProductsDir, cat);
        if (fs.statSync(catPath).isDirectory()) {
          const files = fs.readdirSync(catPath);
          for (const f of files) {
            if (f.includes(cleanFileKey)) {
              fs.unlinkSync(path.join(catPath, f));
            }
          }
        }
      }
    }
    
    // 4. Update file status to "ready" so it gets picked up again
    const mappings = JSON.parse(fs.readFileSync(MAPPINGS_PATH, "utf8"));
    const fileIndex = mappings.files.findIndex(f => f.fileKey === fileKey);
    if (fileIndex !== -1) {
      mappings.files[fileIndex].status = "ready";
      fs.writeFileSync(MAPPINGS_PATH, JSON.stringify(mappings, null, 2));
    }
    
    res.json({ success: true, message: `File ${fileKey} queued for reprocessing` });
  } catch (err) {
    console.error("Reprocess endpoint error:", err);
    res.status(500).json({ error: err.message });
  }
});

// GET /api/missing-products/:fileKey - Get missing products for a file
app.get("/api/missing-products/:fileKey", async (req, res) => {
  try {
    const fileKey = decodeURIComponent(req.params.fileKey);
    const cleanFileKey = fileKey.replace(/\.csv$/i, "").replace(/\//g, "_");
    
    const missingProductsDir = path.join(__dirname, "missing-products");
    let allMissing = [];
    let categories = [];
    
    if (fs.existsSync(missingProductsDir)) {
      const catDirs = fs.readdirSync(missingProductsDir);
      for (const cat of catDirs) {
        const catPath = path.join(missingProductsDir, cat);
        if (fs.statSync(catPath).isDirectory()) {
          const files = fs.readdirSync(catPath);
          const matchingFile = files.find(f => f.includes(cleanFileKey));
          if (matchingFile) {
            const filePath = path.join(catPath, matchingFile);
            try {
              const missingData = JSON.parse(fs.readFileSync(filePath, "utf8"));
              allMissing = allMissing.concat(missingData);
              categories.push(cat.replace("missing-", ""));
            } catch (e) {
              console.error("Error reading missing products:", e.message);
            }
          }
        }
      }
    }
    
    res.json({ 
      count: allMissing.length, 
      categories: [...new Set(categories)],
      products: allMissing 
    });
  } catch (err) {
    console.error("Missing products endpoint error:", err);
    res.status(500).json({ error: err.message });
  }
});

// POST /api/missing-products/:fileKey/create - Trigger create-missing-products script
app.post("/api/missing-products/:fileKey/create", async (req, res) => {
  try {
    const fileKey = decodeURIComponent(req.params.fileKey);
    const cleanFileKey = fileKey.replace(/\.csv$/i, "").replace(/\//g, "_");
    const { categorySlug } = req.body;
    
    if (!categorySlug) {
      return res.status(400).json({ error: "categorySlug is required" });
    }
    
    // Find the missing products file
    const missingDir = path.join(__dirname, "missing-products", `missing-${categorySlug}`);
    const missingFile = `missing_products_${cleanFileKey}.json`;
    const missingFilePath = path.join(missingDir, missingFile);
    
    if (!fs.existsSync(missingFilePath)) {
      return res.status(404).json({ error: `No missing products file found for category ${categorySlug}` });
    }
    
    // Execute the create-missing-products script
    const { exec } = require("child_process");
    const command = `node create-missing-products.js ${categorySlug} ${fileKey}`;
    
    exec(command, { cwd: __dirname }, (error, stdout, stderr) => {
      if (error) {
        console.error("Create products error:", error);
        return res.status(500).json({ error: error.message, stderr });
      }
      res.json({ success: true, output: stdout });
    });
  } catch (err) {
    console.error("Create products endpoint error:", err);
    res.status(500).json({ error: err.message });
  }
});

// DELETE /api/csv-mappings/:fileKey - Delete a file registration
app.delete("/api/csv-mappings/:fileKey", async (req, res) => {
  try {
    const fileKey = decodeURIComponent(req.params.fileKey);
    
    const mappings = JSON.parse(fs.readFileSync(MAPPINGS_PATH, "utf8"));
    const initialLength = mappings.files.length;
    mappings.files = mappings.files.filter(f => f.fileKey !== fileKey);
    
    if (mappings.files.length === initialLength) {
      return res.status(404).json({ error: "File not found" });
    }
    
    fs.writeFileSync(MAPPINGS_PATH, JSON.stringify(mappings, null, 2));
    res.json({ success: true, message: `Deleted ${fileKey}` });
  } catch (err) {
    console.error("Delete endpoint error:", err);
    res.status(500).json({ error: err.message });
  }
});

console.log("[csv-mapping-server] Enhanced endpoints loaded");

// POST /api/trigger-processing - Restart woo-update-app to pick up ready files
app.post("/api/trigger-processing", async (req, res) => {
  try {
    const { exec } = require("child_process");
    exec("pm2 restart woo-update-app", (error, stdout, stderr) => {
      if (error) {
        console.error("Trigger processing error:", error);
        return res.status(500).json({ error: error.message });
      }
      res.json({ success: true, message: "Processing triggered" });
    });
  } catch (err) {
    console.error("Trigger processing error:", err);
    res.status(500).json({ error: err.message });
  }
});